# --- LIBRER√çAS BASE ---
import streamlit as st
import os
import tempfile
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import openai

# --- VIDEO Y EMOCIONES ---
import cv2
from deepface import DeepFace
from scipy.signal import butter, lfilter

# --- LLM (NUEVA VERSI√ìN OPENAI >= 1.0.0) ---
from openai import OpenAI

# --- INICIO APP ---
st.title("üî¨ MVP de Neuromarketing - An√°lisis Facial y BPM por segundo")

# Subir video
video_file = st.file_uploader("üì§ Sube tu video interactuando con el producto (.mp4)", type=["mp4"])
if not video_file:
    st.warning("üëÜ Por favor, sube un video para comenzar el an√°lisis.")
    st.stop()

# Mostrar video
st.video(video_file)

# Guardar temporalmente
temp_video = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
temp_video.write(video_file.read())
video_path = temp_video.name

# Leer video
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)
total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
duration = total_frames / fps
st.write(f"üé• FPS: {fps:.1f}, Duraci√≥n: {duration:.1f}s, Frames: {total_frames}")

# An√°lisis por segundo
frame_emociones = []
bpm_signal = []

st.write("‚è≥ Analizando emociones y BPM...")

for segundo in range(int(duration)):
    cap.set(cv2.CAP_PROP_POS_MSEC, segundo * 1000)
    ret, frame = cap.read()
    if not ret:
        continue

    try:
        # --- Emoci√≥n facial ---
        temp_frame_path = os.path.join(tempfile.gettempdir(), f"frame_{segundo}.jpg")
        cv2.imwrite(temp_frame_path, frame)
        emo_result = DeepFace.analyze(temp_frame_path, actions=["emotion"], enforce_detection=False)
        emociones_completas = emo_result[0]["emotion"] if isinstance(emo_result, list) else emo_result["emotion"]

        # Eliminar emociones no deseadas
        emociones = {k: v for k, v in emociones_completas.items() if k not in ["sad", "angry", "fear"]}

        # Recalcular dominante solo con las emociones restantes
        dominante = max(emociones, key=emociones.get) if emociones else "neutral"

        # --- BPM: media del canal verde del rostro ---
        y, x, h, w = 50, 50, 100, 100
        roi = frame[y:y+h, x:x+w]
        green = roi[:, :, 1].mean()

        frame_emociones.append({
            "Segundo": segundo,
            "Emoci√≥n dominante": dominante,
            "BPM estimado": green,
            **emociones
        })
        bpm_signal.append(green)

    except Exception as e:
        st.warning(f"‚ö†Ô∏è Error en el segundo {segundo}: {e}")

cap.release()

# --- Filtrar se√±al BPM estimada ---
# --- Procesamiento simple de se√±al BPM (reescalado visual entre 60 y 100) ---
if len(bpm_signal) > 5:
    bpm_filtered = np.gradient(bpm_signal)
    raw_values = [abs(x) for x in bpm_filtered]

    min_val = min(raw_values)
    max_val = max(raw_values)
    bpm_bpm = [
        60 + 40 * (v - min_val) / (max_val - min_val) if max_val > min_val else 70
        for v in raw_values
    ]
else:
    bpm_bpm = [70] * len(bpm_signal)  # valor neutro si hay pocos datos

# Agregar BPM corregido al dataframe
for i in range(len(frame_emociones)):
    frame_emociones[i]["BPM final"] = round(bpm_bpm[i], 2) if i < len(bpm_bpm) else None

df = pd.DataFrame(frame_emociones)
st.success("‚úÖ An√°lisis completo.")
st.dataframe(df)

# --- GRAFICAR EMOCIONES DOMINANTES ---
st.subheader("üìä Emoci√≥n dominante por segundo")
fig1, ax1 = plt.subplots()
ax1.plot(df["Segundo"], df["Emoci√≥n dominante"], marker='o')
ax1.set_xlabel("Segundo")
ax1.set_ylabel("Emoci√≥n dominante")
plt.xticks(rotation=90)
st.pyplot(fig1)

# --- GRAFICAR BPM ---
st.subheader("üìà BPM estimado por segundo")
fig2, ax2 = plt.subplots()
ax2.plot(df["Segundo"], df["BPM final"], marker='o', color='green')
ax2.set_xlabel("Segundo")
ax2.set_ylabel("BPM")
st.pyplot(fig2)

# --- Descripci√≥n manual por segundo ---
st.subheader("üìù Describe manualmente lo que hace el usuario (por tramos)")
narrativa = st.text_area("Escribe aqu√≠ tu descripci√≥n", height=200, placeholder="Ej: del 0 al 5 abre la bebida, del 6 al 10 la huele...")

# --- OpenAI GPT An√°lisis ---
st.subheader("üß† An√°lisis estrat√©gico con IA de Neuromarketing")

# Validar que el DataFrame existe
if 'df' not in locals() or df.empty:
    st.error("‚ùå No se generaron datos para el an√°lisis. Verifica que el video tenga rostro visible.")
    st.stop()

# --- TRANSCRIPCI√ìN DE AUDIO ---
import speech_recognition as sr
import moviepy.editor as mp

st.subheader("üó£Ô∏è Transcripci√≥n autom√°tica del audio del video")

# Extraer audio del video a .wav
audio_path = os.path.join(tempfile.gettempdir(), "audio_temp.wav")
try:
    videoclip = mp.VideoFileClip(video_path)
    videoclip.audio.write_audiofile(audio_path, verbose=False, logger=None)
except Exception as e:
    st.error(f"‚ùå Error extrayendo el audio del video: {e}")
    audio_path = None

# Transcribir audio con SpeechRecognition
transcripcion = ""
if audio_path:
    recognizer = sr.Recognizer()
    with sr.AudioFile(audio_path) as source:
        audio_data = recognizer.record(source)

    try:
        transcripcion = recognizer.recognize_google(audio_data, language="es-ES")
        st.success("‚úÖ Transcripci√≥n completada.")
        st.text_area("üìù Transcripci√≥n detectada:", transcripcion, height=150)
    except Exception as e:
        st.warning(f"‚ö†Ô∏è No se pudo transcribir el audio: {e}")


# --- Configurar el cliente OpenAI (versi√≥n nueva >=1.0.0) ---
from openai import OpenAI

client = OpenAI(api_key="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")  # üîë Reemplaza con tu clave segura

try:
    emocion_predominante = df["Emoci√≥n dominante"].mode()[0] if not df.empty else "indefinida"
    bpm_promedio = np.mean(df["BPM final"].dropna())
    tabla = df[["Segundo", "Emoci√≥n dominante", "BPM final"]].to_string(index=False)

    # Validar narrativa y transcripci√≥n
    if narrativa.strip() == "":
        st.warning("‚ö†Ô∏è Escribe una narrativa manual antes de generar el informe.")
        st.stop()

    if transcripcion.strip() == "":
        transcripcion = "(no se detect√≥ audio v√°lido)"

    # Prompt para GPT con tabla, narrativa y transcripci√≥n
    prompt = f"""
Eres un consultor experto en neuromarketing, comportamiento del consumidor y marketing sensorial. Analiza el siguiente estudio:

- Un usuario interact√∫a con un producto (por ejemplo, una bebida).
- Se registraron sus emociones por segundo (an√°lisis facial), su BPM (ritmo card√≠aco) y lo que dice mientras lo manipula.
- A continuaci√≥n, se presenta una descripci√≥n manual de lo que hizo en el video, una transcripci√≥n autom√°tica del audio, y una tabla con las emociones y BPM por segundo.

Descripci√≥n del comportamiento:
{narrativa}

Transcripci√≥n autom√°tica del audio:
{transcripcion}

Tabla de datos emocionales y fisiol√≥gicos:
{tabla}

Entrega un an√°lisis estructurado con:
1. Resumen emocional por etapa
2. An√°lisis fisiol√≥gico (BPM)
3. Coherencia entre lo que hace, dice y siente
4. Reacciones emocionales espec√≠ficas ante el producto f√≠sico observado: ¬øqu√© partes del objeto (empaque, forma, color, textura) generan respuestas emocionales positivas o negativas?, ¬øhay momentos clave de conexi√≥n o rechazo?
5. Asociaci√≥n entre lo que el usuario ve, dice y siente: ¬øc√≥mo responde emocionalmente a los est√≠mulos visuales concretos?, ¬øhay elementos que provocan sorpresa, agrado, confianza o incomodidad?, ¬øqu√© implicaciones tiene esto para el dise√±o visual o sensorial?

No repitas la tabla ni la narrativa. Escribe como si entregar√°s un informe profesional a una marca global.
"""

    # Solicitud a OpenAI
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "Eres un experto en neuromarketing y marketing sensorial."},
            {"role": "user", "content": prompt}
        ],
        temperature=0.75,
        max_tokens=1000
    )

    resultado = response.choices[0].message.content
    st.markdown("### üìã Informe profesional generado por IA:")
    st.markdown(resultado)

except Exception as e:
    st.error(f"‚ùå Error al generar el an√°lisis con OpenAI: {e}")
